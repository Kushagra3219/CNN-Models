{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIrcdhIgpGyRi5baTeTrIy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushagra3219/CNN-Models/blob/main/Marine_Survelillance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqkMynrsCaq0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Marine Surveillance Pipeline using YOLOv8 (EO + IR fusion, tracking, size estimation)\n",
        "\n",
        "- EO stream: visible camera / video file\n",
        "- IR stream: thermal camera / video file\n",
        "- Detection: YOLOv8\n",
        "- Fusion: late fusion between EO & IR detections\n",
        "- Tracking: simple IOU-based tracker with linear motion model\n",
        "- Size estimation: monocular geometry (needs camera calibration + tuning)\n",
        "\n",
        "NOTE:\n",
        "- This is a TEMPLATE / REFERENCE implementation.\n",
        "- You MUST plug in your real camera parameters, paths, and possibly replace the tracker with DeepSORT/ByteTrack for production.\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import math\n",
        "from collections import deque\n",
        "\n",
        "# =========================\n",
        "# CONFIGURATION\n",
        "# =========================\n",
        "\n",
        "# Paths to EO and IR video (or use camera indices like 0, 1)\n",
        "EO_SOURCE = \"eo_video.mp4\"   # change to 0 for webcam\n",
        "IR_SOURCE = \"ir_video.mp4\"   # or another source\n",
        "\n",
        "# YOLO model path (use a pretrained or your fine-tuned marine model)\n",
        "YOLO_MODEL_PATH = \"yolov8n.pt\"  # change to your marine-trained weights\n",
        "\n",
        "# Detection settings\n",
        "CONF_THRES = 0.3\n",
        "IOU_THRES_NMS = 0.5\n",
        "\n",
        "# Tracker settings\n",
        "MAX_TRACK_AGE = 20   # frames to keep \"lost\" tracks\n",
        "IOU_MATCH_THRESH = 0.3\n",
        "\n",
        "# Camera geometry (example values: YOU MUST CALIBRATE THESE)\n",
        "CAMERA_HEIGHT_M = 15.0        # height of camera above sea level (meters)\n",
        "FOCAL_LENGTH_PIXELS = 1200.0  # approx focal length in pixels from calibration\n",
        "HORIZON_ROW = 200             # y-pixel coordinate of horizon line in EO image\n",
        "PRINCIPAL_POINT = (640, 360)  # (cx, cy) for 1280x720 camera\n",
        "\n",
        "FRAME_WIDTH = 1280\n",
        "FRAME_HEIGHT = 720\n",
        "\n",
        "# Optional: labels (if your YOLO model is custom)\n",
        "CLASS_NAMES = None  # or e.g. [\"cargo\", \"tanker\", \"fishing\", \"small_boat\", ...]\n",
        "\n",
        "# Output recording\n",
        "WRITE_OUTPUT = False\n",
        "OUTPUT_PATH = \"output_eo_annotated.mp4\"\n",
        "\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "\n",
        "def iou(box1, box2):\n",
        "    \"\"\"\n",
        "    box: [x1, y1, x2, y2]\n",
        "    \"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return 0.0\n",
        "\n",
        "    inter_area = (x2 - x1) * (y2 - y1)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    return inter_area / float(box1_area + box2_area - inter_area + 1e-6)\n",
        "\n",
        "\n",
        "def draw_box_with_label(img, box, label, color=(0, 255, 0), thickness=2):\n",
        "    x1, y1, x2, y2 = [int(v) for v in box]\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "    if label:\n",
        "        cv2.rectangle(img, (x1, y1 - 20), (x1 + 200, y1), color, -1)\n",
        "        cv2.putText(img, label, (x1 + 2, y1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# SIMPLE IOU-BASED TRACKER\n",
        "# =========================\n",
        "\n",
        "class Track:\n",
        "    def __init__(self, track_id, box, cls, conf, frame_idx):\n",
        "        self.track_id = track_id\n",
        "        self.box = box  # [x1, y1, x2, y2]\n",
        "        self.cls = cls\n",
        "        self.conf = conf\n",
        "        self.last_seen = frame_idx\n",
        "        self.age = 0  # how many frames alive\n",
        "        self.history = deque(maxlen=30)  # store centers for trajectory\n",
        "\n",
        "    def update(self, box, conf, frame_idx):\n",
        "        self.box = box\n",
        "        self.conf = conf\n",
        "        self.last_seen = frame_idx\n",
        "        self.age += 1\n",
        "        cx = 0.5 * (box[0] + box[2])\n",
        "        cy = 0.5 * (box[1] + box[3])\n",
        "        self.history.append((cx, cy))\n",
        "\n",
        "\n",
        "class SimpleTracker:\n",
        "    def __init__(self, iou_match_thresh=0.3, max_age=20):\n",
        "        self.iou_match_thresh = iou_match_thresh\n",
        "        self.max_age = max_age\n",
        "        self.tracks = []\n",
        "        self.next_id = 1\n",
        "\n",
        "    def update(self, detections, frame_idx):\n",
        "        \"\"\"\n",
        "        detections: list of dicts {box, cls, conf}\n",
        "        returns list of Track objects (active)\n",
        "        \"\"\"\n",
        "        # Step 1: match existing tracks to new detections using IoU\n",
        "        unmatched_tracks = set(range(len(self.tracks)))\n",
        "        unmatched_dets = set(range(len(detections)))\n",
        "        matches = []\n",
        "\n",
        "        for ti, track in enumerate(self.tracks):\n",
        "            best_iou = 0.0\n",
        "            best_di = None\n",
        "            for di, det in enumerate(detections):\n",
        "                if di not in unmatched_dets:\n",
        "                    continue\n",
        "                iou_val = iou(track.box, det[\"box\"])\n",
        "                if iou_val > best_iou:\n",
        "                    best_iou = iou_val\n",
        "                    best_di = di\n",
        "            if best_di is not None and best_iou >= self.iou_match_thresh:\n",
        "                matches.append((ti, best_di))\n",
        "                unmatched_tracks.discard(ti)\n",
        "                unmatched_dets.discard(best_di)\n",
        "\n",
        "        # Step 2: update matched tracks\n",
        "        for ti, di in matches:\n",
        "            det = detections[di]\n",
        "            self.tracks[ti].update(det[\"box\"], det[\"conf\"], frame_idx)\n",
        "            self.tracks[ti].cls = det[\"cls\"]\n",
        "\n",
        "        # Step 3: create new tracks for unmatched detections\n",
        "        for di in unmatched_dets:\n",
        "            det = detections[di]\n",
        "            new_track = Track(\n",
        "                self.next_id, det[\"box\"], det[\"cls\"], det[\"conf\"], frame_idx\n",
        "            )\n",
        "            new_track.update(det[\"box\"], det[\"conf\"], frame_idx)\n",
        "            self.tracks.append(new_track)\n",
        "            self.next_id += 1\n",
        "\n",
        "        # Step 4: remove old tracks\n",
        "        active_tracks = []\n",
        "        for t in self.tracks:\n",
        "            if frame_idx - t.last_seen <= self.max_age:\n",
        "                active_tracks.append(t)\n",
        "        self.tracks = active_tracks\n",
        "\n",
        "        return self.tracks\n",
        "\n",
        "\n",
        "# =========================\n",
        "# SIZE & DISTANCE ESTIMATION\n",
        "# =========================\n",
        "\n",
        "def estimate_distance_from_horizon(y_bottom, camera_height=CAMERA_HEIGHT_M,\n",
        "                                   focal_pixels=FOCAL_LENGTH_PIXELS,\n",
        "                                   horizon_row=HORIZON_ROW):\n",
        "    \"\"\"\n",
        "    Very rough distance estimation using sea horizon geometry:\n",
        "    - Assumes flat sea surface.\n",
        "    - y_bottom: bottom of vessel bounding box (in pixels, from top).\n",
        "\n",
        "    Derived from simple pinhole model:\n",
        "    Z = (h * f) / (v_h - v)\n",
        "\n",
        "    Needs calibration and may be unstable close to horizon.\n",
        "    \"\"\"\n",
        "    v = y_bottom\n",
        "    vh = horizon_row\n",
        "    if v <= vh:  # above horizon? invalid\n",
        "        return None\n",
        "\n",
        "    Z = (camera_height * focal_pixels) / float(v - vh + 1e-6)\n",
        "    if Z < 0:\n",
        "        return None\n",
        "    return Z  # meters (approx)\n",
        "\n",
        "\n",
        "def estimate_length_from_box(box, distance_m,\n",
        "                             focal_pixels=FOCAL_LENGTH_PIXELS,\n",
        "                             principal_point=PRINCIPAL_POINT):\n",
        "    \"\"\"\n",
        "    Estimate vessel physical length from bounding box width in pixels:\n",
        "    L_real = (box_width_pixels * Z) / f\n",
        "\n",
        "    Very approximate; you should improve using segmentation mask,\n",
        "    and better calibration.\n",
        "    \"\"\"\n",
        "    if distance_m is None:\n",
        "        return None\n",
        "\n",
        "    x1, y1, x2, y2 = box\n",
        "    width_px = max(1.0, (x2 - x1))\n",
        "    L_real = (width_px * distance_m) / float(focal_pixels)\n",
        "    return L_real\n",
        "\n",
        "\n",
        "# =========================\n",
        "# YOLOv8 DETECTION WRAPPER\n",
        "# =========================\n",
        "\n",
        "class YOLODetector:\n",
        "    def __init__(self, model_path, conf_thres=0.3, iou_thres=0.5):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.conf_thres = conf_thres\n",
        "        self.iou_thres = iou_thres\n",
        "\n",
        "    def detect(self, frame_bgr):\n",
        "        \"\"\"\n",
        "        Run YOLOv8 on a single BGR frame.\n",
        "        Returns list of detection dicts: {box, conf, cls}\n",
        "        \"\"\"\n",
        "        # ultralytics expects RGB or BGR; it can handle BGR directly\n",
        "        results = self.model.predict(\n",
        "            source=frame_bgr,\n",
        "            conf=self.conf_thres,\n",
        "            iou=self.iou_thres,\n",
        "            verbose=False\n",
        "        )\n",
        "        dets = []\n",
        "        if len(results) == 0:\n",
        "            return dets\n",
        "\n",
        "        r = results[0]\n",
        "        if r.boxes is None or len(r.boxes) == 0:\n",
        "            return dets\n",
        "\n",
        "        boxes = r.boxes.xyxy.cpu().numpy()\n",
        "        scores = r.boxes.conf.cpu().numpy()\n",
        "        classes = r.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "        for box, score, cls_id in zip(boxes, scores, classes):\n",
        "            dets.append({\n",
        "                \"box\": box.tolist(),\n",
        "                \"conf\": float(score),\n",
        "                \"cls\": int(cls_id)\n",
        "            })\n",
        "        return dets\n",
        "\n",
        "\n",
        "# =========================\n",
        "# FUSION (EO + IR LATE FUSION)\n",
        "# =========================\n",
        "\n",
        "def fuse_detections_late(EO_dets, IR_dets, iou_thresh=0.5):\n",
        "    \"\"\"\n",
        "    Simple late fusion:\n",
        "    - If EO and IR boxes overlap (IoU > iou_thresh), average their scores.\n",
        "    - Otherwise, keep them as independent detections.\n",
        "\n",
        "    In practice, you might weight EO more in day and IR more at night,\n",
        "    and also enforce class consistency.\n",
        "    \"\"\"\n",
        "    fused = []\n",
        "    used_ir = set()\n",
        "\n",
        "    # Match EO with IR\n",
        "    for eo in EO_dets:\n",
        "        best_iou = 0.0\n",
        "        best_ir_idx = None\n",
        "        for i, ir in enumerate(IR_dets):\n",
        "            if i in used_ir:\n",
        "                continue\n",
        "            val = iou(eo[\"box\"], ir[\"box\"])\n",
        "            if val > best_iou:\n",
        "                best_iou = val\n",
        "                best_ir_idx = i\n",
        "        if best_ir_idx is not None and best_iou >= iou_thresh:\n",
        "            ir = IR_dets[best_ir_idx]\n",
        "            used_ir.add(best_ir_idx)\n",
        "            # simple score fusion: mean of confidences\n",
        "            fused_conf = 0.5 * (eo[\"conf\"] + ir[\"conf\"])\n",
        "            fused_cls = eo[\"cls\"]  # or choose by higher conf\n",
        "            fused_box = eo[\"box\"]  # or average coordinates\n",
        "            fused.append({\n",
        "                \"box\": fused_box,\n",
        "                \"conf\": fused_conf,\n",
        "                \"cls\": fused_cls\n",
        "            })\n",
        "        else:\n",
        "            fused.append(eo)\n",
        "\n",
        "    # Add IR-only detections (not matched)\n",
        "    for i, ir in enumerate(IR_dets):\n",
        "        if i not in used_ir:\n",
        "            fused.append(ir)\n",
        "\n",
        "    return fused\n",
        "\n",
        "\n",
        "# =========================\n",
        "# MAIN LOOP\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # Video capture\n",
        "    eo_cap = cv2.VideoCapture(EO_SOURCE)\n",
        "    ir_cap = cv2.VideoCapture(IR_SOURCE)\n",
        "\n",
        "    if not eo_cap.isOpened():\n",
        "        print(\"Error: Cannot open EO source\")\n",
        "        return\n",
        "    if not ir_cap.isOpened():\n",
        "        print(\"Warning: Cannot open IR source (will run EO only)\")\n",
        "\n",
        "    # Optional set resolution\n",
        "    eo_cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
        "    eo_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
        "\n",
        "    # YOLO detector\n",
        "    detector_eo = YOLODetector(YOLO_MODEL_PATH, CONF_THRES, IOU_THRES_NMS)\n",
        "    detector_ir = YOLODetector(YOLO_MODEL_PATH, CONF_THRES, IOU_THRES_NMS)\n",
        "\n",
        "    # Tracker\n",
        "    tracker = SimpleTracker(IOU_MATCH_THRESH, MAX_TRACK_AGE)\n",
        "\n",
        "    # Output writer\n",
        "    writer = None\n",
        "    if WRITE_OUTPUT:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        writer = cv2.VideoWriter(OUTPUT_PATH, fourcc, 20.0,\n",
        "                                 (FRAME_WIDTH, FRAME_HEIGHT))\n",
        "\n",
        "    frame_idx = 0\n",
        "    fps_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        ret_eo, frame_eo = eo_cap.read()\n",
        "        ret_ir, frame_ir = ir_cap.read() if ir_cap.isOpened() else (False, None)\n",
        "\n",
        "        if not ret_eo:\n",
        "            print(\"EO stream ended.\")\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "        # Resize if needed\n",
        "        frame_eo = cv2.resize(frame_eo, (FRAME_WIDTH, FRAME_HEIGHT))\n",
        "        if ret_ir and frame_ir is not None:\n",
        "            frame_ir = cv2.resize(frame_ir, (FRAME_WIDTH, FRAME_HEIGHT))\n",
        "\n",
        "        # Detection on EO and IR\n",
        "        eo_dets = detector_eo.detect(frame_eo)\n",
        "        ir_dets = detector_ir.detect(frame_ir) if ret_ir and frame_ir is not None else []\n",
        "\n",
        "        # Fuse detections\n",
        "        fused_dets = fuse_detections_late(eo_dets, ir_dets, iou_thresh=0.5)\n",
        "\n",
        "        # Tracking\n",
        "        tracks = tracker.update(fused_dets, frame_idx)\n",
        "\n",
        "        # Draw detections & tracking info + size estimation\n",
        "        for t in tracks:\n",
        "            box = t.box\n",
        "            cls_id = t.cls\n",
        "            conf = t.conf\n",
        "\n",
        "            # Estimate distance from bottom of box\n",
        "            x1, y1, x2, y2 = [int(v) for v in box]\n",
        "            y_bottom = y2\n",
        "            distance_m = estimate_distance_from_horizon(\n",
        "                y_bottom,\n",
        "                camera_height=CAMERA_HEIGHT_M,\n",
        "                focal_pixels=FOCAL_LENGTH_PIXELS,\n",
        "                horizon_row=HORIZON_ROW\n",
        "            )\n",
        "            length_m = estimate_length_from_box(\n",
        "                box,\n",
        "                distance_m,\n",
        "                focal_pixels=FOCAL_LENGTH_PIXELS,\n",
        "                principal_point=PRINCIPAL_POINT\n",
        "            )\n",
        "\n",
        "            # Build label\n",
        "            if CLASS_NAMES is not None and 0 <= cls_id < len(CLASS_NAMES):\n",
        "                cls_name = CLASS_NAMES[cls_id]\n",
        "            else:\n",
        "                cls_name = f\"cls{cls_id}\"\n",
        "\n",
        "            dist_str = f\"{distance_m:.1f}m\" if distance_m is not None else \"?\"\n",
        "            len_str = f\"{length_m:.1f}m\" if length_m is not None else \"?\"\n",
        "\n",
        "            label = f\"ID {t.track_id} | {cls_name} | {conf:.2f} | D={dist_str} | L={len_str}\"\n",
        "            draw_box_with_label(frame_eo, box, label, color=(0, 255, 0))\n",
        "\n",
        "            # Draw trajectory\n",
        "            if len(t.history) >= 2:\n",
        "                for i in range(1, len(t.history)):\n",
        "                    cv2.line(\n",
        "                        frame_eo,\n",
        "                        (int(t.history[i-1][0]), int(t.history[i-1][1])),\n",
        "                        (int(t.history[i][0]), int(t.history[i][1])),\n",
        "                        (255, 0, 0),\n",
        "                        2\n",
        "                    )\n",
        "\n",
        "        # FPS display\n",
        "        now = time.time()\n",
        "        fps = 1.0 / (now - fps_time)\n",
        "        fps_time = now\n",
        "        cv2.putText(frame_eo, f\"FPS: {fps:.1f}\", (10, 25),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"Marine Surveillance - EO (Fused & Tracked)\", frame_eo)\n",
        "        if writer is not None:\n",
        "            writer.write(frame_eo)\n",
        "\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        if key == 27 or key == ord('q'):\n",
        "            break\n",
        "\n",
        "    eo_cap.release()\n",
        "    if ir_cap.isOpened():\n",
        "        ir_cap.release()\n",
        "    if writer is not None:\n",
        "        writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}